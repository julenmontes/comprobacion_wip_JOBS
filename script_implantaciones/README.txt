DESCARGAR y SUBIR/ACTUALIZAR en cada nueva sesión:
- Quality_rules.csv: 
https://docs.google.com/spreadsheets/d/1aLELrHoXPwm8CSY2a6DN6DRqoIkruHQO37JrQcaZFNM/edit?gid=858048847#gid=858048847
- tablas_implantadas.csv:
https://docs.google.com/spreadsheets/d/1aLELrHoXPwm8CSY2a6DN6DRqoIkruHQO37JrQcaZFNM/edit?gid=1027380665#gid=1027380665

1) Subir en KAGG > DATA > Uploads
- Destination directory:
s3://ada-eu-south-2-sbx-live-gl-kagg-data/data/sandboxes/kagg/data/
- Justification:
analytical use
- Purpose:
analysis

revisamos que se suba ok!

2) Abrimos en KAGG > Sagemaker:
> Domains > kagg-sbx-sagemaker-domain-live > User profiles > (nuestro usuario) > Launch > Studio
Se inicia la sesión de jupyter notebook .... ... .. (paciencia) ... 
Elegimos: Data Science 3.0, python 3, medium y esperamos a que se inicie el kernel ... .. . (paciencia) ... .. .


